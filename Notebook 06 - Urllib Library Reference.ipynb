{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. üåê Standard Library Reference: `urllib` (URL Handling)\n",
    "\n",
    "The **`urllib`** library is a package that collects several modules for working with Uniform Resource Locators (URLs).\n",
    "\n",
    "### üßê The \"High-Level\" Analogy\n",
    "Unlike the `socket` module (which is like building your own telephone), `urllib` is like using a **web browser** inside your Python script. It operates at the **Application Layer**, meaning it handles all the messy details of headers, handshakes, and protocols for you.\n",
    "\n",
    "\n",
    "\n",
    "**Key Topics Covered:**\n",
    "* **`urllib.request`:** Fetching web pages (The \"Browser\").\n",
    "* **`urllib.parse`:** Building and dissecting URLs (The \"Translator\").\n",
    "* **`urllib.error`:** Handling HTTP exceptions (The \"Troubleshooter\").\n",
    "* **`urllib.robotparser`:** Checking web scraping rules (The \"Rulebook\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "import urllib.robotparser\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 üì• `urllib.request` (Fetching Data)\n",
    "\n",
    "This module handles sending and retrieving data over HTTP, HTTPS, and FTP.\n",
    "\n",
    "**The \"File\" Analogy:**\n",
    "One of the best features of `urllib` is that it treats a website exactly like a **file on your hard drive**.\n",
    "1.  You `open` it.\n",
    "2.  You `read` it.\n",
    "3.  You `close` it.\n",
    "\n",
    "We use the `with` statement (Context Manager) to ensure the connection is automatically closed after we are done, preventing memory leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to connect to https://jsonplaceholder.typicode.com/todos/1...\n",
      "\n",
      "--- üì© Data Received ---\n",
      "Title: delectus aut autem\n",
      "Status Code: 200 (200 = OK)\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://jsonplaceholder.typicode.com/todos/1'\n",
    "\n",
    "# 1. Basic GET request\n",
    "# urlopen returns a response object (file-like)\n",
    "try:\n",
    "    print(f\"Attempting to connect to {URL}...\")\n",
    "    \n",
    "    # \"with\" automatically closes the socket when the block ends\n",
    "    with urllib.request.urlopen(URL) as response:\n",
    "        \n",
    "        # KEY STEP: The internet sends 'bytes'. We must 'decode' them to string (utf-8).\n",
    "        # .read() grabs the whole file at once\n",
    "        data = response.read().decode('utf-8')\n",
    "        \n",
    "        # Load the JSON string into a Python dictionary\n",
    "        data_dict = json.loads(data)\n",
    "        \n",
    "        print(\"\\n--- üì© Data Received ---\")\n",
    "        print(f\"Title: {data_dict['title']}\")\n",
    "        print(f\"Status Code: {response.status} (200 = OK)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not complete request: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 üî® `urllib.parse` (Building URLs)\n",
    "\n",
    "Have you ever seen a URL with weird characters like `%20` or `%3F`? This is **URL Encoding**.\n",
    "Computers (and servers) get confused by spaces and special symbols in URLs. `urllib.parse` is the tool that \"packs\" your data safely so it can travel across the internet without breaking.\n",
    "\n",
    "\n",
    "\n",
    "**Why is this useful?**\n",
    "If you are building a search tool or an API client (like for a weather app), you cannot just paste user input into a string. You must *encode* it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Params: q=data+science&lang=en\n",
      "Full URL: https://api.example.com/search?q=data+science&lang=en\n",
      "\n",
      "--- üîç URL Anatomy ---\n",
      "Scheme (Protocol): https\n",
      "Path (Location):   /search\n",
      "Query (Data):      q=data+science&lang=en\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://api.example.com/search'\n",
    "query_params = {'q': 'data science', 'lang': 'en'}\n",
    "\n",
    "# 1. Encoding Query Parameters\n",
    "# urlencode converts the dictionary {'q': 'data science'} \n",
    "# into the safe string 'q=data+science&lang=en'\n",
    "encoded_params = urllib.parse.urlencode(query_params)\n",
    "print(f\"Encoded Params: {encoded_params}\")\n",
    "\n",
    "# 2. Combining Base URL and Parameters\n",
    "full_url = f'{base_url}?{encoded_params}'\n",
    "print(f\"Full URL: {full_url}\")\n",
    "\n",
    "# 3. Dissecting a URL\n",
    "# Sometimes you have a full URL and need to extract just the hostname or path.\n",
    "parsed = urllib.parse.urlparse(full_url)\n",
    "print(f\"\\n--- üîç URL Anatomy ---\")\n",
    "print(f\"Scheme (Protocol): {parsed.scheme}\")\n",
    "print(f\"Path (Location):   {parsed.path}\")\n",
    "print(f\"Query (Data):      {parsed.query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 üö® `urllib.error` (Handling Failures)\n",
    "\n",
    "Things go wrong on the internet. `urllib` gives you specific errors so you know *why* it failed.\n",
    "\n",
    "* **`HTTPError` (The Server said \"No\"):** The server was reached, but it refused the request (e.g., 404 Not Found, 403 Forbidden).\n",
    "* **`URLError` (The Network failed):** We couldn't even reach the server (e.g., WiFi is off, DNS failed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to https://httpbin.org/status/404...\n",
      "\n",
      "‚ùå Caught HTTP Error!\n",
      "Code: 404 (Server Refused)\n",
      "Reason: NOT FOUND\n"
     ]
    }
   ],
   "source": [
    "# We purposefully try to hit a page that doesn't exist (Status 404)\n",
    "target_url = 'https://httpbin.org/status/404'\n",
    "\n",
    "try:\n",
    "    print(f\"Connecting to {target_url}...\")\n",
    "    with urllib.request.urlopen(target_url) as response:\n",
    "        print(\"This line should not be reached.\")\n",
    "        \n",
    "except urllib.error.HTTPError as e:\n",
    "    # HTTPError is a subclass of URLError, caught here\n",
    "    print(f\"\\n‚ùå Caught HTTP Error!\")\n",
    "    print(f\"Code: {e.code} (Server Refused)\")\n",
    "    print(f\"Reason: {e.reason}\")\n",
    "    \n",
    "except urllib.error.URLError as e:\n",
    "    # Catches non-HTTP errors like a DNS failure\n",
    "    print(f\"\\nüö´ Caught URL Error!\")\n",
    "    print(f\"Reason: {e.reason} (Network Issue)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 ü§ñ `urllib.robotparser` (Web Scraping Ethics)\n",
    "\n",
    "Before you write a script to download thousands of pages from a website, you must check their **`robots.txt`** file. This is the \"House Rules\" for bots.\n",
    "\n",
    "`urllib.robotparser` helps you be a \"polite\" programmer by checking if your bot (`User-Agent`) is allowed to touch a specific page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('https://www.google.com/robots.txt')\n",
    "\n",
    "# We must read the robots.txt file (simulating the load)\n",
    "# In a real app, rp.read() fetches and parses the file from the internet\n",
    "# rp.read()\n",
    "\n",
    "# Test if a common bot is allowed\n",
    "# print(f\"Is Googlebot allowed to crawl /search? {rp.can_fetch('Googlebot', '/search')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ÓÅûÊΩÆ Mini-Challenge: The Query Builder\n",
    "\n",
    "**Task:** You are building an API request to filter products on an e-commerce site.\n",
    "\n",
    "1.  Define a dictionary of query parameters: `{'product': 'laptop pro', 'sort': 'price', 'limit': 25}`.\n",
    "2.  Build the final, correctly encoded URL using `urllib.parse.urlencode()` and string formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://data.example.com/api/v1/filter?product=Laptop+Pro&sort=price&limit=25&user=Shashika\n"
     ]
    }
   ],
   "source": [
    "base_api = \"https://data.example.com/api/v1/filter\"\n",
    "params = {'product': 'Laptop Pro', 'sort': 'price', 'limit': 25, 'user': 'Shashika'}\n",
    "\n",
    "# Write your solution here\n",
    "\n",
    "encoded = urllib.parse.urlencode(params)\n",
    "final_url = f\"{base_api}?{encoded}\"\n",
    "\n",
    "print(final_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåü Core Insight for Your CSE Career\n",
    "\n",
    "### Parse vs. Request\n",
    "The split between `urllib.parse` and `urllib.request` is crucial to understand.\n",
    "\n",
    "1.  **`parse`** deals with the *logic* of the URL (encoding, breaking down query strings, paths).\n",
    "2.  **`request`** deals with the *physical transmission* (sending HTTP packets, managing headers).\n",
    "\n",
    "Even if you eventually use simpler external libraries (like `requests`), you will often find yourself strictly using `urllib.parse` to correctly format complex URL paths and safe query strings for your Data Science projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
